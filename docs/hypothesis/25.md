# 25. Поиск пиков нейронной сетью с входным вектором переменного размера

Использовать наработки из [гипотезы 21](21.md). Старая реализация нейронной сети принимала на вход вектор постоянного размера shape=(None, 300, 1). Это делало невозможным ее применение на данных с отличающимся рамером. Единственным вариантом было преобразование данных к нужному размеру. В случае если в данных больше чем 300 элементов происходила потеря данных. Для количества меньше 300 требовалось дополнить данные нолями, что увеличивало обьем вычислений.

Создать ИНС с входным вектором переменного размера shape=(None, None, 1). Такая сверточная сеть может принимать данные произвольной длинны. Таким образом не нужно дополнять данные до фиксированной длинны.

## Допущения

### Шаг по оси Х равен 1

Данные с отличным шагом нужо преобразовать к одиничному, например:

```python
# x - массив точек по оси х
# y - массив значений в точках

new_x = numpy.arange(x[0], x[-1], 1)
new_y = numpy.interp(new_x, x, y)

# new_x - массив точек по оси х с шагом 1
# new_y - массив значений в точках
```

### На вход подаются данные нормированные на 1

Пример нормировки:

```python
# y - массив значений в точках

y_max = numpy.max(y)
if y_max > 0:
    y_norm = y / y_max
    
# y_norm - массив значений в точках, номированный на 1
```

### Размерность входных и выходных данных

Размерность входных и выходных данных: `(N, M, 1)`

Где, N - количество примеров (спектров), M - количество точек в примере (спектре), 1 - количество каналов постоянно.

Например, если набор состоит из 30 спектров, а в каждом по 320 точек, то размерость данных: `(30, 320, 1)`

### Спектр состоит из базовых функций

#### Функция Гаусса

`G(x, mu, sigma, scale)`

#### Функция Лоренца

`L(x, x0, gamma, scale)`

### Порог ответа

Прогноз нейронной сети дополнительно должен быть обработан пороговой функцией.

```python
# z - результат работы нейронной сети
threshold = 0.4
predict = (z > threshold) * z

# predict - итоговый результат
```

## Реализация

### Структура нейронной сети

Сеть состоит исключительно из сверточных слоев. Размер выхода равен размеру входа - сеть не изменяет размер. Елементы выходного массива интерпретируются как вероятность нахождения в соответсвующей точке базовой функции.

Для улучшения точности сеть состоит из множества сверточных слоев. Поскольку каждая точка в определенном слое является сверточным отображением области из предыдыдущего слоя, то с ростом количества слоев растет размер отображаемой в одну точку области. Таким образом можно достичь взаимного влияния близко расположенных пиков и улучшить точность модели. В используемой сети размер отображаемой области ~ 70.

В последнем сверточном слое 1 канал. Это позволяет свернуть все предыдущие каналы в одну точку.

Для повышения точности используется функция обшибки основанная на сверточном уширении отклонения предсказанного значения от истинного.

Для определения точности используется функция основанная на свертке. Она учитывает области вблизи пиков, а отдаленные точки не учитывает. Таким образом берется во внимание важность правильного ответа вблизи цетров базовых функций, а не на удалении от них, где значение всегда близко к нулю.

### Данные

Данные для обучения генерируюются искусственно. Используется динамически генерируемы данные с использованием генераторов языка python. Таким образом достигается большая скрость запуска программы (не нужно заранее генерировать данные) и снимается ограничение на размер датасета.

Генерируемые данные состоят из спектров образованных из случайного числа базовых функций с случайными параметрами. Алгоритм располагает центры вблизи друг друга, чтобы нейронная сеть изучала, что важно, задачу нахождения центров базовых функций, когда они расположены очень близко.

### Функции ошибки

Могут быть использованы одна из следующих функций ошибки.

#### mean_squared_error

Встроенная функция ошибки библиотеки Keras.

#### attention_loss

Функция ошибки внимания. Определяет ошибку только в окресности пиков.

#### sharp_loss

Функция повишения резкости отклонения. С помощью сверточного повышения резкости увеличивает роль области возле пика в формировании ошибки. 

#### exp_loss

Экспоненциальная квадритичная ошибка.

#### adaptive_loss

Адаптивная функция ошибки. При плохом обнаружении пиков определяет ошибку как среднее квадрата отклонения в точках пиков, иначе, как среднее квадрата отклонений во всех точках. Переход между вариантами непрерывный.

### Метрики

#### true_accuracy

Среднее значение точности в точках пиков.

#### area_accuracy

Средняя точность во всех точках окресностей пиков с даметром D.

## Результаты

Была получена точность выше 65% по метрике true_accuracy и 87% по метрике area_accuracy с диаметром 15 после 1000 эпох обучения. Лучшие результаты показала функция ошибки adaptive_loss. Визуальный анализ показал, что нейронная сеть хорошо определяет центры базовых функций, даже в случаях сильного наложения.

Есть потенциал повышения точности за счет дополнительного обучения и подбора более подходящей архитектуры сети.
