## Гипотеза #1

Имеем спектр люминисценции вещества, состоящий из функций, которые нам нужно определить.
Предположим, что определить можно используя сверточную нейронную сеть.

**Структура нейронной сети:**

* Вход - по частотной ширине и дискретизации спектра. Спектр по оси длинны волны располагается с 250 по 700 нм. Входных нейронов 700-250 = 450 штук. Входные данные в диапазоне [0,1].
* Сверточный слой (32)
* Сверточный слой (32)
* Сверточный слой (32)
* Полносвязный слой (450)
* Выход - тип функции А или Б.

**Проверочные данные:**
* Синтетические данные
* Определяемые функции: Гаусса, Лагранжа
* Параметры функций: переменная, смещение

**Требуемый вывод:** может-ли сверточная сеть определить тип функции?

**Файл:** [hypothesis_1.py](/approximate/hypothesis_1.py)

**Результат:** тип функции распознается почти с 100% точностью.


## Гипотеза #2

Как изменяется точность распознавание при наличии шумов?

**Проверочные данные:**

* Зашумленные данные

**Требуемый вывод:** с какой точностью сверточная сеть определяет тип функции при наличии шумов?

**Файл:** [hypothesis_2.py](/approximate/hypothesis_2.py)

**Результат:**
    При амплитуде шумов 0.033 точность 99.6 %.
    При амплитуде шумов 0.2 (на глаз определить функцию невозможно) точность 76 %.

**Вывод:** точность снижается незначительно


## Гипотеза #3

Определение функций при задании случайными всех изменяемых параметров.

**Проверочные данные:**

* Параметрый функций:

**Гаусса:** аргумент х, мю (мат. ожидание, медиана, мода), сигма (среднеквадратичное отклонение, корень дисперсии)
        
**Лоренца:** аргумент х, x_0 (параметр сдвига), gamma (параметр масштаба)
        
**Войта (псевдо-Войт):** -
        
**Пирсона:** -

**Требуемый вывод:** как изменяется точность работы сети?

**Файл:** [hypothesis_3.py](/approximate/hypothesis_3.py)

**Результат:** при изменяемых параметрах точность работы сети остается очень высокой ~ 98 %


## Гипотеза #4

То же что и #3, только с нормировкой на 1 и добавлением шумов.

**Требуемый вывод:** как изменяется точность работы сети?

**Файл:** [hypothesis_4.py](/approximate/hypothesis_4.py)

**Результат:**

Точность без шумов 99.9 %

Точность с шумами 90 %

Очевидна значительное падение точности. Судя по точности на различных эпохах сеть застряла - нужно менять архитектуру.


## Гипотеза #5

Сможет-ли поднять точность добавление dropout слоя?

**Файл:** [hypothesis_5.py](/approximate/hypothesis_5.py)

**Результат:** точность 99.75 %, при тех же равных в #4 точность была 94.4 %


## Гипотеза #6

То же что и в #4 только с большим по размеру ядром свертки.

**Файл:** [hypothesis_6.py](/approximate/hypothesis_6.py)
**Результат:** при увеличении ядра свертки с 5 до 9 точность 99.7 %


## Гипотеза #7

То же что и в #4 только с дополнительными слоями свертки.

**Файл:** [hypothesis_7.py](/approximate/hypothesis_7.py)

**Результат:**

Добавление 1 слоя: точность 94.8 %

Добавление 2 слоя: точность 90 %


**Вывод из #5, 6, 7:** добавить dropout, изменить размер ядра свертки, дополнительные слои под вопросом.


## Гипотеза #10

Определение типа функции, смещения и параметров, при условии, что функция одна.

**Файл:** [hypothesis_10.py](/approximate/hypothesis_10.py)

**Результат:** функция определяется с точностью близкой к 100%


## Гипотеза #20

Нейросеть анализирует спектр на наличие пиков.

**Структура сети:** два слоя сверки, последний слой - полносвязный

**Файл:** [hypothesis_20.py](/approximate/hypothesis_20.py)

**Результат:** Получена точность на уровне 80%. Обучение длительное. Проблемой является большое количество параметров: 2.9 млн. В полносвязном слое находяться 99.99% этих параметров. В двух сверточных слоях количество параметров: 200 + 5150. Уменьшение количества параметров может драматически повысить скорость обучения сети.


## Гипотеза #21

Данные подаваемые на полносвязный слой обладают теми же особенностями что и в сверточных слоях. А именно - симметрия сдвига. Исходя из этого предлагается полносвязный слой заменить на слой уменьшающий размероность. Данные в определенной точке спектра создаются набором фильтров. Эти значения должны быть преобразованы некоторой функцией в одно число. Использовать функцию: максимум.

**Файл:** [hypothesis_21.py](/approximate/hypothesis_21.py)

**Результат:** Использованы слои Conv1 и MaxPooling1D. Количество параметров ~ 15000. Точность после длительного обучения 35%, не смотря на это нейронная сеть показывает визуально хорошие результаты. Прогнозируемые пики хорошо соотносятся с реальными.


## Гипотеза #nn

Спаренные нейросети. Первая определяет в спектре пики, которые нужно доисследовать. Вторая применяется на пиках и определяет их параметры.
